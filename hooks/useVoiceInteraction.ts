"use client";

import { useCallback, useRef, useEffect } from 'react';
import { speechToText } from '@/services/asr';
import { chatStream } from '@/services/chat';
import { useChatStore } from '@/store/chatStore';
import { useAvatarStore } from '@/store/avatarStore';
import { useLanguageStore } from '@/store/languageStore';
import { useWakeStore } from '@/store/wakeStore';
import { useTTSQueueStore } from '@/store/ttsQueueStore';
import { extractSentences, processRemainingText } from '@/utils/sentenceExtractor';
import { useTTSExecutor } from '@/hooks/useTTSExecutor';
import { useLipsyncPlayer, PreparedLipsyncData } from '@/hooks/useLipsyncPlayer';

/** ç”Ÿæˆå”¯ä¸€ ID */
function generateId(): string {
  return `${Date.now()}-${Math.random().toString(36).slice(2, 9)}`;
}

/**
 * è¯­éŸ³äº¤äº’ Hook
 * å¤„ç†å®Œæ•´çš„è¯­éŸ³äº¤äº’æµç¨‹ï¼šASR -> Chat -> TTSï¼ˆå¥å­çº§åˆ†æ®µï¼‰ -> Lip-sync æ’­æ”¾
 */
export function useVoiceInteraction() {
  const { addMessage, updateMessageContent, updateMessageStatus } = useChatStore();
  const { setAction, lipsyncEnabled, faceFileId, setLipsyncMode } = useAvatarStore();
  const { language } = useLanguageStore();
  const { isProcessing, setIsProcessing, setPhase, reset } = useWakeStore();
  
  // TTS é˜Ÿåˆ—æ“ä½œ
  const { addTask, clearQueue: clearTTSQueue, reset: resetTTSQueue } = useTTSQueueStore();
  
  // Lip-sync æ’­æ”¾å™¨ï¼ˆæ”¯æŒå¹¶è¡Œé¢„ç”Ÿæˆ + é¡ºåºæ’­æ”¾ï¼‰
  const { prepare: prepareLipsync, playPrepared, stop: stopLipsync, isPlaying: isLipsyncPlaying } = useLipsyncPlayer();
  
  // Lip-sync å¹¶å‘æ§åˆ¶
  const MAX_CONCURRENT_PREPARE = 2;  // æœ€å¤§åŒæ—¶è¿›è¡Œçš„é¢„ç”Ÿæˆä»»åŠ¡æ•°
  const activePrepareCountRef = useRef(0);  // å½“å‰æ­£åœ¨è¿›è¡Œçš„é¢„ç”Ÿæˆä»»åŠ¡æ•°
  const pendingAudioQueueRef = useRef<Uint8Array[]>([]);  // ç­‰å¾…é¢„ç”Ÿæˆçš„éŸ³é¢‘é˜Ÿåˆ—
  
  // Lip-sync é¢„ç”Ÿæˆé˜Ÿåˆ—ï¼ˆå­˜å‚¨ Promiseï¼Œå¯ä»¥å¹¶è¡Œé¢„ç”Ÿæˆï¼‰
  const lipsyncPrepareQueueRef = useRef<Array<Promise<PreparedLipsyncData>>>([]);
  // æ’­æ”¾å¾ªç¯æ˜¯å¦åœ¨è¿è¡Œ
  const isLipsyncLoopRunningRef = useRef(false);
  
  const audioQueueRef = useRef<Array<{ audio: HTMLAudioElement; url: string }>>([]);
  const playingRef = useRef(false);
  const drainResolvers = useRef<Array<() => void>>([]);
  
  // è¿½è¸ªå½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘ï¼ˆå·²ä»é˜Ÿåˆ—ç§»å‡ºï¼‰
  const currentAudioRef = useRef<{ audio: HTMLAudioElement; url: string } | null>(null);
  
  // ç”¨äºå–æ¶ˆæ­£åœ¨è¿›è¡Œçš„è¯·æ±‚
  const abortControllerRef = useRef<AbortController | null>(null);
  
  // æ ‡è®°æ˜¯å¦è¢«æ‰“æ–­ï¼ˆé¿å… finally é‡å¤é‡ç½®çŠ¶æ€ï¼‰
  const wasInterruptedRef = useRef(false);
  
  // å¥å­ç¼“å†²åŒºï¼ˆç”¨äºæµå¼ Chat æ—¶æå–å®Œæ•´å¥å­ï¼‰
  const sentenceBufferRef = useRef('');

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†éŸ³é¢‘èµ„æº
  useEffect(() => {
    return () => {
      // å–æ¶ˆè¿›è¡Œä¸­çš„è¯·æ±‚
      abortControllerRef.current?.abort();
      abortControllerRef.current = null;
      
      // åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
      if (currentAudioRef.current) {
        currentAudioRef.current.audio.pause();
        URL.revokeObjectURL(currentAudioRef.current.url);
        currentAudioRef.current = null;
      }
      
      // æ¸…ç†é˜Ÿåˆ—
      for (const item of audioQueueRef.current) {
        item.audio.pause();
        URL.revokeObjectURL(item.url);
      }
      audioQueueRef.current = [];
      playingRef.current = false;
      
      // æ¸…ç† TTS é˜Ÿåˆ—
      clearTTSQueue();
      
      // æ¸…ç† Lip-sync
      lipsyncPrepareQueueRef.current = [];
      pendingAudioQueueRef.current = [];
      activePrepareCountRef.current = 0;
      isLipsyncLoopRunningRef.current = false;
      stopLipsync();
    };
  }, [clearTTSQueue, stopLipsync]);

  const resolveDrain = useCallback(() => {
    if (audioQueueRef.current.length === 0 && !playingRef.current) {
      drainResolvers.current.forEach((fn) => fn());
      drainResolvers.current = [];
    }
  }, []);

  const playNextRef = useRef<() => void>(() => {});
  useEffect(() => {
    playNextRef.current = () => {
      if (playingRef.current) return;
      const next = audioQueueRef.current.shift();
      if (!next) {
        currentAudioRef.current = null;
        setAction('idle');
        resolveDrain();
        return;
      }

      playingRef.current = true;
      currentAudioRef.current = next; // è¿½è¸ªå½“å‰æ’­æ”¾çš„éŸ³é¢‘
      const { audio, url } = next;

      audio.onplay = () => setAction('talk');
      audio.onended = () => {
        URL.revokeObjectURL(url);
        currentAudioRef.current = null;
        playingRef.current = false;
        playNextRef.current();
      };
      audio.onerror = (e) => {
        console.error('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', e);
        URL.revokeObjectURL(url);
        currentAudioRef.current = null;
        playingRef.current = false;
        playNextRef.current();
      };

      audio.play().catch((err) => {
        console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', err);
        URL.revokeObjectURL(url);
        currentAudioRef.current = null;
        playingRef.current = false;
        playNextRef.current();
      });
    };
  }, [resolveDrain, setAction]);

  const enqueueAudio = useCallback(
    (bytes: Uint8Array) => {
      // Copy into a fresh Uint8Array to avoid SharedArrayBuffer typing issues
      const safeBytes = new Uint8Array(bytes);
      const blob = new Blob([safeBytes], { type: 'audio/mp3' });
      const url = URL.createObjectURL(blob);
      const audio = new Audio(url);
      audioQueueRef.current.push({ audio, url });
      playNextRef.current();
    },
    []
  );

  const waitForDrain = useCallback(() => {
    if (!playingRef.current && audioQueueRef.current.length === 0) return Promise.resolve();
    return new Promise<void>((resolve) => {
      drainResolvers.current.push(resolve);
    });
  }, []);

  // Lip-sync ç­‰å¾…é˜Ÿåˆ—å®Œæˆ
  const waitForLipsyncDrain = useCallback(() => {
    if (!isLipsyncLoopRunningRef.current && lipsyncPrepareQueueRef.current.length === 0) {
      return Promise.resolve();
    }
    return new Promise<void>((resolve) => {
      drainResolvers.current.push(resolve);
    });
  }, []);

  /**
   * Lip-sync æ’­æ”¾å¾ªç¯
   * æŒ‰é¡ºåºç­‰å¾…é¢„ç”Ÿæˆå®Œæˆå¹¶æ’­æ”¾
   */
  const runLipsyncPlayLoop = useCallback(async () => {
    if (isLipsyncLoopRunningRef.current) return;
    isLipsyncLoopRunningRef.current = true;
    
    console.log('ğŸ¬ Lip-sync æ’­æ”¾å¾ªç¯å¼€å§‹');
    
    while (lipsyncPrepareQueueRef.current.length > 0) {
      // å–å‡ºé˜Ÿé¦–çš„ Promise
      const preparePromise = lipsyncPrepareQueueRef.current.shift()!;
      
      try {
        // ç­‰å¾…é¢„ç”Ÿæˆå®Œæˆ
        console.log('â³ ç­‰å¾…é¢„ç”Ÿæˆå®Œæˆ...');
        setLipsyncMode('buffering');
        const preparedData = await preparePromise;
        
        // æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
        if (wasInterruptedRef.current) {
          console.log('æ’­æ”¾å¾ªç¯è¢«æ‰“æ–­');
          break;
        }
        
        // æ’­æ”¾ï¼ˆplayPrepared ä¼šåœ¨é¦–å¸§æ¸²æŸ“åè‡ªåŠ¨è®¾ç½® lipsyncMode='playing'ï¼‰
        console.log('â–¶ï¸ æ’­æ”¾å¯¹å£å‹');
        
        await playPrepared(preparedData, {
          onPlayStart: () => {
            // åœ¨ Canvas æ˜¾ç¤ºåï¼ˆé¦–å¸§å·²æ¸²æŸ“ï¼‰å†åˆ‡æ¢çŠ¶æ€ï¼Œé¿å…é—ªçƒ
            setPhase('speaking');
            setAction('talk');
          },
          onPlayEnd: () => {
            console.log('âœ… ä¸€å¥æ’­æ”¾å®Œæˆ');
          },
          onError: (error) => {
            console.error('Lip-sync æ’­æ”¾é”™è¯¯:', error);
          },
        });
        
      } catch (error) {
        // AbortError æˆ–å·²æ‰“æ–­çš„æƒ…å†µï¼Œé™é»˜é€€å‡º
        if (wasInterruptedRef.current || 
            (error instanceof Error && error.name === 'AbortError') ||
            (error instanceof DOMException && error.name === 'AbortError')) {
          console.log('Lip-sync é¢„ç”Ÿæˆè¢«å–æ¶ˆ');
          break;
        }
        console.error('Lip-sync å¤„ç†é”™è¯¯:', error);
      }
    }
    
    // å¾ªç¯ç»“æŸ
    isLipsyncLoopRunningRef.current = false;
    
    // å¦‚æœä¸æ˜¯è¢«æ‰“æ–­çš„ï¼Œæ¢å¤åˆ° idle çŠ¶æ€
    if (!wasInterruptedRef.current) {
      setAction('idle');
      setPhase('idle');
      setLipsyncMode('idle');
    }
    
    // é€šçŸ¥ç­‰å¾…è€…
    drainResolvers.current.forEach((fn) => fn());
    drainResolvers.current = [];
    
    console.log('ğŸ¬ Lip-sync æ’­æ”¾å¾ªç¯ç»“æŸ');
  }, [playPrepared, setAction, setPhase, setLipsyncMode]);

  /**
   * å¯åŠ¨ä¸€ä¸ªé¢„ç”Ÿæˆä»»åŠ¡ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
   */
  const startPrepareTask = useCallback((audioBytes: Uint8Array) => {
    if (!faceFileId) return;
    
    activePrepareCountRef.current++;
    console.log(`ğŸ“¤ å¼€å§‹é¢„ç”Ÿæˆ lip-sync å¸§ (å¹¶å‘: ${activePrepareCountRef.current}/${MAX_CONCURRENT_PREPARE})`);
    
    const preparePromise = prepareLipsync(
      faceFileId, 
      audioBytes, 
      abortControllerRef.current?.signal
    ).finally(() => {
      // ä»»åŠ¡å®Œæˆï¼ˆæˆåŠŸæˆ–å¤±è´¥ï¼‰ï¼Œå‡å°‘è®¡æ•°
      activePrepareCountRef.current--;
      
      // æ£€æŸ¥ç­‰å¾…é˜Ÿåˆ—ï¼Œå¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡
      if (pendingAudioQueueRef.current.length > 0 && activePrepareCountRef.current < MAX_CONCURRENT_PREPARE) {
        const nextAudio = pendingAudioQueueRef.current.shift()!;
        startPrepareTask(nextAudio);
      }
    });
    
    // åŠ å…¥é¢„ç”Ÿæˆé˜Ÿåˆ—
    lipsyncPrepareQueueRef.current.push(preparePromise);
    
    // å¯åŠ¨æ’­æ”¾å¾ªç¯ï¼ˆå¦‚æœå°šæœªè¿è¡Œï¼‰
    runLipsyncPlayLoop().catch(err => {
      if (err?.name !== 'AbortError') {
        console.error('Lip-sync æ’­æ”¾å¾ªç¯é”™è¯¯:', err);
      }
    });
  }, [faceFileId, prepareLipsync, runLipsyncPlayLoop]);

  // å¤„ç†éŸ³é¢‘çš„å›è°ƒï¼ˆåˆ¤æ–­æ˜¯å¦å¯ç”¨ lip-syncï¼‰
  const handleAudio = useCallback((audioBytes: Uint8Array) => {
    if (lipsyncEnabled && faceFileId) {
      // æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°
      if (activePrepareCountRef.current < MAX_CONCURRENT_PREPARE) {
        // æœªè¾¾åˆ°ä¸Šé™ï¼Œç«‹å³å¯åŠ¨é¢„ç”Ÿæˆ
        startPrepareTask(audioBytes);
      } else {
        // è¾¾åˆ°ä¸Šé™ï¼ŒåŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        console.log(`â¸ï¸ é¢„ç”Ÿæˆä»»åŠ¡å·²æ»¡ (${MAX_CONCURRENT_PREPARE})ï¼ŒåŠ å…¥ç­‰å¾…é˜Ÿåˆ—`);
        pendingAudioQueueRef.current.push(audioBytes);
      }
    } else {
      // é™çº§ï¼šä½¿ç”¨åŸæœ‰éŸ³é¢‘æ’­æ”¾
      enqueueAudio(audioBytes);
    }
  }, [lipsyncEnabled, faceFileId, enqueueAudio, startPrepareTask]);

  // TTS æ‰§è¡Œå™¨
  const { 
    startProcessing: startTTSProcessing, 
    stopAndClear: stopTTSProcessing,
    waitForAllComplete: waitForTTSComplete,
  } = useTTSExecutor({
    maxConcurrent: 2,
    onAudio: handleAudio,
    signal: abortControllerRef.current?.signal,
  });

  /**
   * æ‰“æ–­å½“å‰å›å¤
   * åœæ­¢éŸ³é¢‘æ’­æ”¾ã€å–æ¶ˆæµå¼è¯·æ±‚ã€é‡ç½®çŠ¶æ€
   */
  const interrupt = useCallback(() => {
    console.log('ğŸ›‘ ç”¨æˆ·æ‰“æ–­å›å¤');
    
    // æ ‡è®°å·²è¢«æ‰“æ–­
    wasInterruptedRef.current = true;
    
    // 1. å–æ¶ˆè¿›è¡Œä¸­çš„è¯·æ±‚
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
    }
    
    // 2. åœæ­¢ TTS å¤„ç†å¹¶æ¸…ç©ºé˜Ÿåˆ—
    stopTTSProcessing();
    
    // 3. æ¸…ç©º Lip-sync é¢„ç”Ÿæˆé˜Ÿåˆ—å¹¶åœæ­¢å½“å‰æ’­æ”¾
    lipsyncPrepareQueueRef.current = [];
    pendingAudioQueueRef.current = [];
    activePrepareCountRef.current = 0;
    isLipsyncLoopRunningRef.current = false;
    stopLipsync();
    
    // 4. åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘ï¼ˆé™çº§æ¨¡å¼ï¼‰
    if (currentAudioRef.current) {
      currentAudioRef.current.audio.pause();
      URL.revokeObjectURL(currentAudioRef.current.url);
      currentAudioRef.current = null;
    }
    
    // 5. æ¸…ç©ºéŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—
    for (const item of audioQueueRef.current) {
      item.audio.pause();
      URL.revokeObjectURL(item.url);
    }
    audioQueueRef.current = [];
    playingRef.current = false;
    
    // 6. æ¸…ç©ºå¥å­ç¼“å†²åŒº
    sentenceBufferRef.current = '';
    
    // 7. é‡ç½®çŠ¶æ€ï¼ˆä½¿ç”¨å•ä¸€ action ä¿è¯åŸå­æ€§ï¼‰
    setAction('idle');
    setLipsyncMode('idle');
    reset(); // åŒæ—¶é‡ç½® isProcessing å’Œ phase
    
    // 8. æ¸…ç† drain resolvers
    drainResolvers.current.forEach((fn) => fn());
    drainResolvers.current = [];
  }, [setAction, setLipsyncMode, reset, stopTTSProcessing, stopLipsync]);

  // å¤„ç†æ–‡æœ¬è¾“å…¥ï¼ˆæµå¼è¯­éŸ³è¯†åˆ«åç›´æ¥è°ƒç”¨ï¼‰
  const handleTextInput = useCallback(async (userText: string) => {
    if (isProcessing || !userText.trim()) return;
    
    // é‡ç½®æ‰“æ–­æ ‡è®°å’Œå¥å­ç¼“å†²åŒº
    wasInterruptedRef.current = false;
    sentenceBufferRef.current = '';
    
    // é‡ç½® TTS é˜Ÿåˆ—å’Œ Lip-sync é˜Ÿåˆ—
    resetTTSQueue();
    lipsyncPrepareQueueRef.current = [];
    pendingAudioQueueRef.current = [];
    activePrepareCountRef.current = 0;
    isLipsyncLoopRunningRef.current = false;
    
    setIsProcessing(true);
    setPhase('thinking'); // å¼€å§‹æ€è€ƒ
    setAction('think');   // è¿›å…¥æ€è€ƒçŠ¶æ€ï¼Œæ’­æ”¾ think.mp4
    const msgId = generateId();
    const botMsgId = generateId();
    
    // åˆ›å»ºæ–°çš„ AbortController
    abortControllerRef.current = new AbortController();
    const signal = abortControllerRef.current.signal;

    // æ ‡è®°æ˜¯å¦å·²å¼€å§‹è¯´è¯ï¼ˆå¯¹äº lip-sync æ¨¡å¼ï¼Œæ­¤æ ‡è®°ä¸å†ç”¨äºåˆ‡æ¢ phaseï¼‰
    let hasSentFirstSentence = false;

    try {
      console.log('ğŸ“ å¤„ç†ç”¨æˆ·è¾“å…¥:', userText);

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
      addMessage({
        id: msgId,
        role: 'user',
        content: userText,
        status: 'success',
        timestamp: Date.now(),
      });

      // æ·»åŠ  AI å ä½æ¶ˆæ¯
      addMessage({
        id: botMsgId,
        role: 'ai',
        content: '',
        status: 'loading',
        timestamp: Date.now(),
      });

      // å¯åŠ¨ TTS æ‰§è¡Œå™¨ï¼ˆå‡†å¤‡æ¥æ”¶ä»»åŠ¡ï¼‰
      startTTSProcessing();

      // Chat: å‘é€ç»™ AIï¼ˆæµå¼å“åº”ï¼‰
      let fullBotResponse = '';
      console.log('ğŸ¤– å‘é€ç»™ AI...');
      
      await chatStream(
        userText,
        (chunk) => {
          fullBotResponse += chunk;
          sentenceBufferRef.current += chunk;
          updateMessageContent(botMsgId, fullBotResponse);
          
          // å®æ—¶æå–å®Œæ•´å¥å­
          const { completeSentences, remaining } = extractSentences(sentenceBufferRef.current);
          sentenceBufferRef.current = remaining;
          
          // ç«‹å³å°†å®Œæ•´å¥å­åŠ å…¥ TTS é˜Ÿåˆ—
          for (const sentence of completeSentences) {
            console.log('ğŸ“¤ å¥å­å…¥é˜Ÿ:', sentence);
            addTask(sentence);
            
            // ç¬¬ä¸€ä¸ªå¥å­å…¥é˜Ÿæ—¶ï¼Œåˆ‡æ¢åˆ° speaking é˜¶æ®µï¼ˆä»…é™çº§æ¨¡å¼ï¼‰
            // lip-sync æ¨¡å¼ä¸‹ï¼Œphase ç”±æ’­æ”¾å™¨åœ¨å¸§å°±ç»ªæ—¶åˆ‡æ¢
            if (!hasSentFirstSentence && !lipsyncEnabled) {
              hasSentFirstSentence = true;
              setPhase('speaking');
              console.log('ğŸ”Š å¼€å§‹å¥å­çº§æµå¼è¯­éŸ³åˆæˆï¼ˆé™çº§æ¨¡å¼ï¼‰...');
            }
          }
        },
        {
          language,
          systemPrompt: 'Please respond in English.',
          signal,
        }
      );
      
      updateMessageStatus(botMsgId, 'success');
      console.log('ğŸ¤– AI å›å¤å®Œæˆ:', fullBotResponse);
      
      if (!fullBotResponse) {
        throw new Error('AI å›å¤ä¸ºç©º');
      }

      // å¤„ç†å‰©ä½™çš„ä¸å®Œæ•´å¥å­
      const remainingChunks = processRemainingText(sentenceBufferRef.current);
      for (const chunk of remainingChunks) {
        console.log('ğŸ“¤ å‰©ä½™æ–‡æœ¬å…¥é˜Ÿ:', chunk);
        addTask(chunk);
        
        // å¯¹äºé™çº§æ¨¡å¼ï¼ˆé lip-syncï¼‰ï¼Œåœ¨è¿™é‡Œåˆ‡æ¢ phase
        if (!hasSentFirstSentence && !lipsyncEnabled) {
          hasSentFirstSentence = true;
          setPhase('speaking');
        }
      }
      sentenceBufferRef.current = '';

      // ç­‰å¾…æ‰€æœ‰ TTS ä»»åŠ¡å®Œæˆ
      await waitForTTSComplete();
      
      // ç­‰å¾…æ’­æ”¾å®Œæˆï¼ˆæ ¹æ®æ˜¯å¦å¯ç”¨ lip-sync é€‰æ‹©ç­‰å¾…å“ªä¸ªé˜Ÿåˆ—ï¼‰
      if (lipsyncEnabled && faceFileId) {
        await waitForLipsyncDrain();
      } else {
        await waitForDrain();
        setPhase('idle'); // é™çº§æ¨¡å¼ä¸‹åœ¨è¿™é‡Œé‡ç½® phase
        setAction('idle');
      }
      // lip-sync æ¨¡å¼ä¸‹ï¼Œphase å’Œ action ç”± playNextLipsyncRef åœ¨é˜Ÿåˆ—æ’­æ”¾å®Œæˆæ—¶é‡ç½®

    } catch (error) {
      // å¦‚æœæ˜¯ç”¨æˆ·æ‰“æ–­å¯¼è‡´çš„å–æ¶ˆï¼Œä¸è§†ä¸ºé”™è¯¯
      if (signal.aborted || wasInterruptedRef.current) {
        console.log('ğŸ›‘ è¯·æ±‚å·²è¢«ç”¨æˆ·æ‰“æ–­');
        // å¦‚æœæœ‰éƒ¨åˆ†å“åº”ï¼Œæ ‡è®°ä¸ºæˆåŠŸï¼ˆå·²æ˜¾ç¤ºçš„å†…å®¹ï¼‰
        const currentContent = useChatStore.getState().messages.find(m => m.id === botMsgId)?.content;
        if (currentContent) {
          updateMessageStatus(botMsgId, 'success');
        }
        // çŠ¶æ€å·²åœ¨ interrupt() ä¸­é‡ç½®ï¼Œç›´æ¥è¿”å›
        return;
      }
      
      console.error('è¯­éŸ³äº¤äº’é”™è¯¯:', error);
      setAction('idle');
      setPhase('idle');
      updateMessageStatus(botMsgId, 'error');
    } finally {
      // æ¸…ç† controller å¼•ç”¨
      if (abortControllerRef.current?.signal === signal) {
        abortControllerRef.current = null;
      }
      // åªæœ‰éæ‰“æ–­æƒ…å†µæ‰åœ¨ finally ä¸­é‡ç½®çŠ¶æ€ï¼ˆæ‰“æ–­æ—¶å·²åœ¨ interrupt() ä¸­é‡ç½®ï¼‰
      if (!wasInterruptedRef.current) {
        setIsProcessing(false);
      }
    }
  }, [
    addMessage,
    updateMessageContent,
    updateMessageStatus,
    setAction,
    setPhase,
    setIsProcessing,
    isProcessing,
    waitForDrain,
    waitForLipsyncDrain,
    language,
    addTask,
    resetTTSQueue,
    startTTSProcessing,
    waitForTTSComplete,
    lipsyncEnabled,
    faceFileId,
  ]);

  // å¤„ç†è¯­éŸ³è¾“å…¥ï¼ˆå½•éŸ³åè°ƒç”¨ï¼Œéœ€è¦å…ˆ ASRï¼‰
  const handleVoiceInput = useCallback(async (audioBlob: Blob) => {
    if (isProcessing) return;
    
    setIsProcessing(true);
    const botMsgId = generateId();

    try {
      // ASR: è¯­éŸ³è½¬æ–‡å­—
      console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«ä¸­...');
      const userText = await speechToText(audioBlob);
      console.log('ğŸ¤ è¯†åˆ«ç»“æœ:', userText);

      if (!userText.trim()) {
        setIsProcessing(false);
        return;
      }

      // é‡ç½®å¤„ç†çŠ¶æ€ï¼Œè®© handleTextInput æ¥ç®¡
      setIsProcessing(false);
      await handleTextInput(userText);

    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', error);
      setAction('idle');
      setIsProcessing(false);
      updateMessageStatus(botMsgId, 'error');
    }
  }, [handleTextInput, setAction, updateMessageStatus, isProcessing, setIsProcessing]);

  return {
    isProcessing,
    handleVoiceInput,
    handleTextInput,
    interrupt,
  };
}
