"use client";

import { useCallback, useRef, useEffect } from 'react';
import { speechToText } from '@/services/asr';
import { chatStream } from '@/services/chat';
import { useChatStore } from '@/store/chatStore';
import { useAvatarStore } from '@/store/avatarStore';
import { useLanguageStore } from '@/store/languageStore';
import { useWakeStore } from '@/store/wakeStore';
import { useTTSQueueStore } from '@/store/ttsQueueStore';
import { extractSentences, processRemainingText } from '@/utils/sentenceExtractor';
import { useTTSExecutor } from '@/hooks/useTTSExecutor';

/** ç”Ÿæˆå”¯ä¸€ ID */
function generateId(): string {
  return `${Date.now()}-${Math.random().toString(36).slice(2, 9)}`;
}

/**
 * è¯­éŸ³äº¤äº’ Hook
 * å¤„ç†å®Œæ•´çš„è¯­éŸ³äº¤äº’æµç¨‹ï¼šASR -> Chat -> TTSï¼ˆå¥å­çº§åˆ†æ®µï¼‰ -> æ’­æ”¾
 */
export function useVoiceInteraction() {
  const { addMessage, updateMessageContent, updateMessageStatus } = useChatStore();
  const { setAction } = useAvatarStore();
  const { language } = useLanguageStore();
  const { isProcessing, setIsProcessing, setPhase, reset } = useWakeStore();
  
  // TTS é˜Ÿåˆ—æ“ä½œ
  const { addTask, clearQueue: clearTTSQueue, reset: resetTTSQueue } = useTTSQueueStore();
  
  const audioQueueRef = useRef<Array<{ audio: HTMLAudioElement; url: string }>>([]);
  const playingRef = useRef(false);
  const drainResolvers = useRef<Array<() => void>>([]);
  
  // è¿½è¸ªå½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘ï¼ˆå·²ä»é˜Ÿåˆ—ç§»å‡ºï¼‰
  const currentAudioRef = useRef<{ audio: HTMLAudioElement; url: string } | null>(null);
  
  // ç”¨äºå–æ¶ˆæ­£åœ¨è¿›è¡Œçš„è¯·æ±‚
  const abortControllerRef = useRef<AbortController | null>(null);
  
  // æ ‡è®°æ˜¯å¦è¢«æ‰“æ–­ï¼ˆé¿å… finally é‡å¤é‡ç½®çŠ¶æ€ï¼‰
  const wasInterruptedRef = useRef(false);
  
  // å¥å­ç¼“å†²åŒºï¼ˆç”¨äºæµå¼ Chat æ—¶æå–å®Œæ•´å¥å­ï¼‰
  const sentenceBufferRef = useRef('');

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†éŸ³é¢‘èµ„æº
  useEffect(() => {
    return () => {
      // å–æ¶ˆè¿›è¡Œä¸­çš„è¯·æ±‚
      abortControllerRef.current?.abort();
      abortControllerRef.current = null;
      
      // åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
      if (currentAudioRef.current) {
        currentAudioRef.current.audio.pause();
        URL.revokeObjectURL(currentAudioRef.current.url);
        currentAudioRef.current = null;
      }
      
      // æ¸…ç†é˜Ÿåˆ—
      for (const item of audioQueueRef.current) {
        item.audio.pause();
        URL.revokeObjectURL(item.url);
      }
      audioQueueRef.current = [];
      playingRef.current = false;
      
      // æ¸…ç† TTS é˜Ÿåˆ—
      clearTTSQueue();
    };
  }, [clearTTSQueue]);

  const resolveDrain = useCallback(() => {
    if (audioQueueRef.current.length === 0 && !playingRef.current) {
      drainResolvers.current.forEach((fn) => fn());
      drainResolvers.current = [];
    }
  }, []);

  const playNextRef = useRef<() => void>(() => {});
  useEffect(() => {
    playNextRef.current = () => {
      if (playingRef.current) return;
      const next = audioQueueRef.current.shift();
      if (!next) {
        currentAudioRef.current = null;
        setAction('idle');
        resolveDrain();
        return;
      }

      playingRef.current = true;
      currentAudioRef.current = next; // è¿½è¸ªå½“å‰æ’­æ”¾çš„éŸ³é¢‘
      const { audio, url } = next;

      audio.onplay = () => setAction('talk');
      audio.onended = () => {
        URL.revokeObjectURL(url);
        currentAudioRef.current = null;
        playingRef.current = false;
        playNextRef.current();
      };
      audio.onerror = (e) => {
        console.error('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', e);
        URL.revokeObjectURL(url);
        currentAudioRef.current = null;
        playingRef.current = false;
        playNextRef.current();
      };

      audio.play().catch((err) => {
        console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', err);
        URL.revokeObjectURL(url);
        currentAudioRef.current = null;
        playingRef.current = false;
        playNextRef.current();
      });
    };
  }, [resolveDrain, setAction]);

  const enqueueAudio = useCallback(
    (bytes: Uint8Array) => {
      // Copy into a fresh Uint8Array to avoid SharedArrayBuffer typing issues
      const safeBytes = new Uint8Array(bytes);
      const blob = new Blob([safeBytes], { type: 'audio/mp3' });
      const url = URL.createObjectURL(blob);
      const audio = new Audio(url);
      audioQueueRef.current.push({ audio, url });
      playNextRef.current();
    },
    []
  );

  const waitForDrain = useCallback(() => {
    if (!playingRef.current && audioQueueRef.current.length === 0) return Promise.resolve();
    return new Promise<void>((resolve) => {
      drainResolvers.current.push(resolve);
    });
  }, []);

  // TTS æ‰§è¡Œå™¨
  const { 
    startProcessing: startTTSProcessing, 
    stopAndClear: stopTTSProcessing,
    waitForAllComplete: waitForTTSComplete,
  } = useTTSExecutor({
    maxConcurrent: 2,
    onAudio: enqueueAudio,
    signal: abortControllerRef.current?.signal,
  });

  /**
   * æ‰“æ–­å½“å‰å›å¤
   * åœæ­¢éŸ³é¢‘æ’­æ”¾ã€å–æ¶ˆæµå¼è¯·æ±‚ã€é‡ç½®çŠ¶æ€
   */
  const interrupt = useCallback(() => {
    console.log('ğŸ›‘ ç”¨æˆ·æ‰“æ–­å›å¤');
    
    // æ ‡è®°å·²è¢«æ‰“æ–­
    wasInterruptedRef.current = true;
    
    // 1. å–æ¶ˆè¿›è¡Œä¸­çš„è¯·æ±‚
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
    }
    
    // 2. åœæ­¢ TTS å¤„ç†å¹¶æ¸…ç©ºé˜Ÿåˆ—
    stopTTSProcessing();
    
    // 3. åœæ­¢å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘
    if (currentAudioRef.current) {
      currentAudioRef.current.audio.pause();
      URL.revokeObjectURL(currentAudioRef.current.url);
      currentAudioRef.current = null;
    }
    
    // 4. æ¸…ç©ºéŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—
    for (const item of audioQueueRef.current) {
      item.audio.pause();
      URL.revokeObjectURL(item.url);
    }
    audioQueueRef.current = [];
    playingRef.current = false;
    
    // 5. æ¸…ç©ºå¥å­ç¼“å†²åŒº
    sentenceBufferRef.current = '';
    
    // 6. é‡ç½®çŠ¶æ€ï¼ˆä½¿ç”¨å•ä¸€ action ä¿è¯åŸå­æ€§ï¼‰
    setAction('idle');
    reset(); // åŒæ—¶é‡ç½® isProcessing å’Œ phase
    
    // 7. æ¸…ç† drain resolvers
    drainResolvers.current.forEach((fn) => fn());
    drainResolvers.current = [];
  }, [setAction, reset, stopTTSProcessing]);

  // å¤„ç†æ–‡æœ¬è¾“å…¥ï¼ˆæµå¼è¯­éŸ³è¯†åˆ«åç›´æ¥è°ƒç”¨ï¼‰
  const handleTextInput = useCallback(async (userText: string) => {
    if (isProcessing || !userText.trim()) return;
    
    // é‡ç½®æ‰“æ–­æ ‡è®°å’Œå¥å­ç¼“å†²åŒº
    wasInterruptedRef.current = false;
    sentenceBufferRef.current = '';
    
    // é‡ç½® TTS é˜Ÿåˆ—
    resetTTSQueue();
    
    setIsProcessing(true);
    setPhase('thinking'); // å¼€å§‹æ€è€ƒ
    const msgId = generateId();
    const botMsgId = generateId();
    
    // åˆ›å»ºæ–°çš„ AbortController
    abortControllerRef.current = new AbortController();
    const signal = abortControllerRef.current.signal;

    // æ ‡è®°æ˜¯å¦å·²å¼€å§‹è¯´è¯
    let hasSentFirstSentence = false;

    try {
      console.log('ğŸ“ å¤„ç†ç”¨æˆ·è¾“å…¥:', userText);

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
      addMessage({
        id: msgId,
        role: 'user',
        content: userText,
        status: 'success',
        timestamp: Date.now(),
      });

      // æ·»åŠ  AI å ä½æ¶ˆæ¯
      addMessage({
        id: botMsgId,
        role: 'ai',
        content: '',
        status: 'loading',
        timestamp: Date.now(),
      });

      // å¯åŠ¨ TTS æ‰§è¡Œå™¨ï¼ˆå‡†å¤‡æ¥æ”¶ä»»åŠ¡ï¼‰
      startTTSProcessing();

      // Chat: å‘é€ç»™ AIï¼ˆæµå¼å“åº”ï¼‰
      let fullBotResponse = '';
      console.log('ğŸ¤– å‘é€ç»™ AI...');
      
      await chatStream(
        userText,
        (chunk) => {
          fullBotResponse += chunk;
          sentenceBufferRef.current += chunk;
          updateMessageContent(botMsgId, fullBotResponse);
          
          // å®æ—¶æå–å®Œæ•´å¥å­
          const { completeSentences, remaining } = extractSentences(sentenceBufferRef.current);
          sentenceBufferRef.current = remaining;
          
          // ç«‹å³å°†å®Œæ•´å¥å­åŠ å…¥ TTS é˜Ÿåˆ—
          for (const sentence of completeSentences) {
            console.log('ğŸ“¤ å¥å­å…¥é˜Ÿ:', sentence);
            addTask(sentence);
            
            // ç¬¬ä¸€ä¸ªå¥å­å…¥é˜Ÿæ—¶ï¼Œåˆ‡æ¢åˆ° speaking é˜¶æ®µ
            if (!hasSentFirstSentence) {
              hasSentFirstSentence = true;
              setPhase('speaking');
              console.log('ğŸ”Š å¼€å§‹å¥å­çº§æµå¼è¯­éŸ³åˆæˆ...');
            }
          }
        },
        {
          language,
          systemPrompt: 'Please respond in English.',
          signal,
        }
      );
      
      updateMessageStatus(botMsgId, 'success');
      console.log('ğŸ¤– AI å›å¤å®Œæˆ:', fullBotResponse);
      
      if (!fullBotResponse) {
        throw new Error('AI å›å¤ä¸ºç©º');
      }

      // å¤„ç†å‰©ä½™çš„ä¸å®Œæ•´å¥å­
      const remainingChunks = processRemainingText(sentenceBufferRef.current);
      for (const chunk of remainingChunks) {
        console.log('ğŸ“¤ å‰©ä½™æ–‡æœ¬å…¥é˜Ÿ:', chunk);
        addTask(chunk);
        
        if (!hasSentFirstSentence) {
          hasSentFirstSentence = true;
          setPhase('speaking');
        }
      }
      sentenceBufferRef.current = '';

      // ç­‰å¾…æ‰€æœ‰ TTS ä»»åŠ¡å®Œæˆ
      await waitForTTSComplete();
      
      // ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ
      await waitForDrain();
      setPhase('idle'); // è¯´å®Œäº†

    } catch (error) {
      // å¦‚æœæ˜¯ç”¨æˆ·æ‰“æ–­å¯¼è‡´çš„å–æ¶ˆï¼Œä¸è§†ä¸ºé”™è¯¯
      if (signal.aborted || wasInterruptedRef.current) {
        console.log('ğŸ›‘ è¯·æ±‚å·²è¢«ç”¨æˆ·æ‰“æ–­');
        // å¦‚æœæœ‰éƒ¨åˆ†å“åº”ï¼Œæ ‡è®°ä¸ºæˆåŠŸï¼ˆå·²æ˜¾ç¤ºçš„å†…å®¹ï¼‰
        const currentContent = useChatStore.getState().messages.find(m => m.id === botMsgId)?.content;
        if (currentContent) {
          updateMessageStatus(botMsgId, 'success');
        }
        // çŠ¶æ€å·²åœ¨ interrupt() ä¸­é‡ç½®ï¼Œç›´æ¥è¿”å›
        return;
      }
      
      console.error('è¯­éŸ³äº¤äº’é”™è¯¯:', error);
      setAction('idle');
      setPhase('idle');
      updateMessageStatus(botMsgId, 'error');
    } finally {
      // æ¸…ç† controller å¼•ç”¨
      if (abortControllerRef.current?.signal === signal) {
        abortControllerRef.current = null;
      }
      // åªæœ‰éæ‰“æ–­æƒ…å†µæ‰åœ¨ finally ä¸­é‡ç½®çŠ¶æ€ï¼ˆæ‰“æ–­æ—¶å·²åœ¨ interrupt() ä¸­é‡ç½®ï¼‰
      if (!wasInterruptedRef.current) {
        setIsProcessing(false);
      }
    }
  }, [
    addMessage,
    updateMessageContent,
    updateMessageStatus,
    setAction,
    setPhase,
    setIsProcessing,
    isProcessing,
    waitForDrain,
    language,
    addTask,
    resetTTSQueue,
    startTTSProcessing,
    waitForTTSComplete,
  ]);

  // å¤„ç†è¯­éŸ³è¾“å…¥ï¼ˆå½•éŸ³åè°ƒç”¨ï¼Œéœ€è¦å…ˆ ASRï¼‰
  const handleVoiceInput = useCallback(async (audioBlob: Blob) => {
    if (isProcessing) return;
    
    setIsProcessing(true);
    const botMsgId = generateId();

    try {
      // ASR: è¯­éŸ³è½¬æ–‡å­—
      console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«ä¸­...');
      const userText = await speechToText(audioBlob);
      console.log('ğŸ¤ è¯†åˆ«ç»“æœ:', userText);

      if (!userText.trim()) {
        setIsProcessing(false);
        return;
      }

      // é‡ç½®å¤„ç†çŠ¶æ€ï¼Œè®© handleTextInput æ¥ç®¡
      setIsProcessing(false);
      await handleTextInput(userText);

    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', error);
      setAction('idle');
      setIsProcessing(false);
      updateMessageStatus(botMsgId, 'error');
    }
  }, [handleTextInput, setAction, updateMessageStatus, isProcessing, setIsProcessing]);

  return {
    isProcessing,
    handleVoiceInput,
    handleTextInput,
    interrupt,
  };
}
