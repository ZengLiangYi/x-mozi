"use client";

import { useState, useRef, useCallback, useEffect } from 'react';
import { FilesetResolver, ObjectDetector } from '@mediapipe/tasks-vision';

/** æ£€æµ‹é—´éš”ï¼ˆæ¯«ç§’ï¼‰ */
const DETECTION_INTERVAL_MS = 200;
/** å”¤é†’æ‰€éœ€æŒç»­æ£€æµ‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
const WAKE_DURATION_MS = 2000;
/** å”¤é†’å†·å´æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
const WAKE_COOLDOWN_MS = 5000;
/** MediaPipe WASM æ–‡ä»¶ CDN è·¯å¾„ */
const MEDIAPIPE_WASM_PATH = 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm';
/** ç‰©ä½“æ£€æµ‹æ¨¡å‹ CDN è·¯å¾„ (EfficientDet-Lite0ï¼Œæ”¯æŒæ£€æµ‹äººä½“) */
const OBJECT_DETECTOR_MODEL_PATH = 'https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite';

export interface UseCameraWakeOptions {
  /** æ£€æµ‹åˆ°äººæŒç»­ 2 ç§’åçš„å›è°ƒ */
  onWakeUp?: () => void;
  /** æ˜¯å¦ç¦ç”¨å”¤é†’ï¼ˆAI æ­£åœ¨å¤„ç†æ—¶åº”è®¾ä¸º trueï¼‰ */
  disabled?: boolean;
}

export interface UseCameraWakeReturn {
  /** æ˜¯å¦æ­£åœ¨æ£€æµ‹ */
  isDetecting: boolean;
  /** é”™è¯¯ä¿¡æ¯ */
  error: string | null;
  /** æ‘„åƒå¤´è§†é¢‘æµï¼ˆç”¨äºé¢„è§ˆï¼‰ */
  mediaStream: MediaStream | null;
  /** å¼€å§‹æ£€æµ‹ */
  startDetecting: () => Promise<void>;
  /** åœæ­¢æ£€æµ‹ */
  stopDetecting: () => void;
}

/**
 * æ‘„åƒå¤´äººè„¸æ£€æµ‹å”¤é†’ Hook
 * 
 * é€šè¿‡æ§åˆ¶å°å¯ç”¨ï¼š
 * window.startCameraWake()  // å¼€å§‹æ£€æµ‹
 * window.stopCameraWake()   // åœæ­¢æ£€æµ‹
 */
export function useCameraWake(options: UseCameraWakeOptions = {}): UseCameraWakeReturn {
  const { onWakeUp, disabled = false } = options;

  // State
  const [isDetecting, setIsDetecting] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [mediaStream, setMediaStream] = useState<MediaStream | null>(null);

  // Refs - èµ„æºå¼•ç”¨
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const objectDetectorRef = useRef<ObjectDetector | null>(null);
  const detectionIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // Refs - çŠ¶æ€å¼•ç”¨
  const personDetectedStartRef = useRef<number | null>(null);
  const lastWakeUpTimeRef = useRef<number>(0);
  const isManualStopRef = useRef(false);
  const disabledRef = useRef(disabled);

  // Refs - å›è°ƒå¼•ç”¨
  const onWakeUpRef = useRef(onWakeUp);

  useEffect(() => {
    onWakeUpRef.current = onWakeUp;
  }, [onWakeUp]);

  // åŒæ­¥ disabled çŠ¶æ€åˆ° ref
  useEffect(() => {
    disabledRef.current = disabled;
    // å½“ç¦ç”¨æ—¶ï¼Œé‡ç½®äººè„¸æ£€æµ‹è®¡æ—¶
    if (disabled) {
      personDetectedStartRef.current = null;
    }
  }, [disabled]);

  // æ¸…ç†æ‰€æœ‰èµ„æº
  const cleanup = useCallback(() => {
    // æ¸…ç†æ£€æµ‹å®šæ—¶å™¨
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }

    // åœæ­¢ MediaStream
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    setMediaStream(null);

    // ç§»é™¤ video å…ƒç´ 
    if (videoRef.current) {
      videoRef.current.srcObject = null;
      videoRef.current.remove();
      videoRef.current = null;
    }

    // å…³é—­ ObjectDetector
    if (objectDetectorRef.current) {
      objectDetectorRef.current.close();
      objectDetectorRef.current = null;
    }

    personDetectedStartRef.current = null;
  }, []);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      isManualStopRef.current = true;
      cleanup();
    };
  }, [cleanup]);

  // åˆå§‹åŒ– ObjectDetectorï¼ˆæ£€æµ‹äººä½“ï¼‰
  const initObjectDetector = useCallback(async (): Promise<ObjectDetector> => {
    const vision = await FilesetResolver.forVisionTasks(MEDIAPIPE_WASM_PATH);
    const objectDetector = await ObjectDetector.createFromOptions(vision, {
      baseOptions: {
        modelAssetPath: OBJECT_DETECTOR_MODEL_PATH,
        delegate: 'GPU',
      },
      runningMode: 'VIDEO',
      scoreThreshold: 0.5,
      categoryAllowlist: ['person'], // åªæ£€æµ‹äºº
    });
    return objectDetector;
  }, []);

  // æ‰§è¡Œäººä½“æ£€æµ‹
  const detectPerson = useCallback(() => {
    const video = videoRef.current;
    const objectDetector = objectDetectorRef.current;

    if (!video || !objectDetector || video.readyState < 2) {
      return;
    }

    // å¦‚æœç¦ç”¨çŠ¶æ€ï¼Œè·³è¿‡æ£€æµ‹é€»è¾‘
    if (disabledRef.current) {
      return;
    }

    try {
      const now = performance.now();
      const detections = objectDetector.detectForVideo(video, now);
      const hasPerson = detections.detections.length > 0;

      if (hasPerson) {
        // æ£€æµ‹åˆ°äºº
        if (personDetectedStartRef.current === null) {
          personDetectedStartRef.current = Date.now();
          console.log('ğŸ‘¤ æ£€æµ‹åˆ°äººï¼Œå¼€å§‹è®¡æ—¶...');
        } else {
          const duration = Date.now() - personDetectedStartRef.current;
          const cooldownElapsed = Date.now() - lastWakeUpTimeRef.current > WAKE_COOLDOWN_MS;

          if (duration >= WAKE_DURATION_MS && cooldownElapsed) {
            console.log('âœ… æŒç»­æ£€æµ‹åˆ°äºº 2 ç§’ï¼Œè§¦å‘å”¤é†’ï¼');
            lastWakeUpTimeRef.current = Date.now();
            personDetectedStartRef.current = null;
            onWakeUpRef.current?.();
          }
        }
      } else {
        // æœªæ£€æµ‹åˆ°äººï¼Œé‡ç½®è®¡æ—¶
        if (personDetectedStartRef.current !== null) {
          console.log('ğŸ‘¤ äººç¦»å¼€ï¼Œé‡ç½®è®¡æ—¶');
          personDetectedStartRef.current = null;
        }
      }
    } catch (err) {
      console.error('äººä½“æ£€æµ‹é”™è¯¯:', err);
    }
  }, []);

  // å¼€å§‹æ£€æµ‹
  const startDetecting = useCallback(async () => {
    if (isDetecting) return;

    isManualStopRef.current = false;
    setError(null);
    personDetectedStartRef.current = null;

    try {
      console.log('ğŸ“· å¼€å§‹æ‘„åƒå¤´äººä½“æ£€æµ‹...');

      // åˆå§‹åŒ– ObjectDetector
      console.log('ğŸ“· åŠ è½½äººä½“æ£€æµ‹æ¨¡å‹...');
      const objectDetector = await initObjectDetector();
      objectDetectorRef.current = objectDetector;
      console.log('ğŸ“· äººä½“æ£€æµ‹æ¨¡å‹åŠ è½½å®Œæˆ');

      // è·å–æ‘„åƒå¤´æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user',
        },
      });
      mediaStreamRef.current = stream;
      setMediaStream(stream);

      // åˆ›å»ºéšè—çš„ video å…ƒç´ 
      const video = document.createElement('video');
      video.srcObject = stream;
      video.style.position = 'absolute';
      video.style.top = '-9999px';
      video.style.left = '-9999px';
      video.playsInline = true;
      video.muted = true;
      document.body.appendChild(video);
      videoRef.current = video;

      // ç­‰å¾…è§†é¢‘åŠ è½½
      await new Promise<void>((resolve, reject) => {
        video.onloadedmetadata = () => {
          video.play()
            .then(() => resolve())
            .catch(reject);
        };
        video.onerror = () => reject(new Error('è§†é¢‘åŠ è½½å¤±è´¥'));
      });

      console.log('ğŸ“· æ‘„åƒå¤´å·²å¯åŠ¨ï¼Œå¼€å§‹æ£€æµ‹äººä½“');
      setIsDetecting(true);

      // å¼€å§‹å®šæ—¶æ£€æµ‹
      detectionIntervalRef.current = setInterval(detectPerson, DETECTION_INTERVAL_MS);

    } catch (err) {
      console.error('å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹å¤±è´¥:', err);
      setError(err instanceof Error ? err.message : 'å¯åŠ¨å¤±è´¥');
      cleanup();
    }
  }, [isDetecting, cleanup, initObjectDetector, detectPerson]);

  // åœæ­¢æ£€æµ‹
  const stopDetecting = useCallback(() => {
    console.log('ğŸ“· åœæ­¢æ‘„åƒå¤´æ£€æµ‹');
    isManualStopRef.current = true;
    cleanup();
    setIsDetecting(false);
  }, [cleanup]);

  return {
    isDetecting,
    error,
    mediaStream,
    startDetecting,
    stopDetecting,
  };
}
