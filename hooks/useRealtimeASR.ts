"use client";

import { useState, useRef, useCallback, useEffect } from 'react';
import { createAudioContext, audiaToPcmBuffer } from '@/utils/audio';
import { TencentAsrResponse, ASR_SLICE_TYPE } from '@/types/asr';
import {
  DEFAULT_SILENCE_TIMEOUT,
  AUDIO_PROCESSOR_PATH,
  AUDIO_PROCESSOR_NAME,
  MICROPHONE_CONSTRAINTS,
} from '@/constants/audio';

export interface UseRealtimeASROptions {
  /** è¯†åˆ«å®Œæˆå›è°ƒï¼ˆVAD æ£€æµ‹åˆ°é™éŸ³åè§¦å‘ï¼‰ */
  onResult?: (text: string) => void;
  /** è¯†åˆ«è¿‡ç¨‹ä¸­çš„å›è°ƒï¼ˆå®æ—¶æ˜¾ç¤ºï¼‰ */
  onInterim?: (text: string) => void;
  /** é™éŸ³è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ */
  silenceTimeout?: number;
}

export interface UseRealtimeASRReturn {
  /** æ˜¯å¦æ­£åœ¨å½•éŸ³ */
  isRecording: boolean;
  /** å½“å‰è¯†åˆ«åˆ°çš„æ–‡æœ¬ */
  transcript: string;
  /** é”™è¯¯ä¿¡æ¯ */
  error: string | null;
  /** MediaStream éŸ³é¢‘æµï¼ˆç”¨äºéŸ³é¢‘å¯è§†åŒ–ï¼‰ */
  mediaStream: MediaStream | null;
  /** å¼€å§‹å½•éŸ³ */
  startRecording: () => Promise<void>;
  /** åœæ­¢å½•éŸ³ */
  stopRecording: () => void;
}

/**
 * å®æ—¶è¯­éŸ³è¯†åˆ« Hook - åŸºäºè…¾è®¯äº‘å®æ—¶ ASR
 * 
 * åŠŸèƒ½ï¼š
 * - ç‚¹å‡»å¼€å§‹å½•éŸ³
 * - å®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ
 * - VAD æ£€æµ‹åˆ°é™éŸ³åè‡ªåŠ¨åœæ­¢å¹¶è¿”å›ç»“æœ
 * - æä¾› MediaStream ç”¨äºéŸ³é¢‘å¯è§†åŒ–
 */
export function useRealtimeASR(options: UseRealtimeASROptions = {}): UseRealtimeASRReturn {
  const {
    onResult,
    onInterim,
    silenceTimeout = DEFAULT_SILENCE_TIMEOUT,
  } = options;

  // State
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [mediaStream, setMediaStream] = useState<MediaStream | null>(null);

  // Refs - èµ„æºå¼•ç”¨
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  
  // Refs - çŠ¶æ€å¼•ç”¨
  const accumulatedTextRef = useRef('');  // å·²ç¡®è®¤çš„ç´¯ç§¯æ–‡æœ¬ï¼ˆfinal ç»“æœï¼‰
  const currentSentenceRef = useRef('');  // å½“å‰å¥å­çš„ä¸´æ—¶æ–‡æœ¬ï¼ˆinterim ç»“æœï¼Œä¼šè¢«æ›¿æ¢ï¼‰
  const silenceTimeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const isStoppedRef = useRef(false);
  
  // Refs - å›è°ƒå¼•ç”¨ï¼ˆé¿å…é—­åŒ…é—®é¢˜ï¼‰
  const onResultRef = useRef(onResult);
  const onInterimRef = useRef(onInterim);
  
  useEffect(() => {
    onResultRef.current = onResult;
    onInterimRef.current = onInterim;
  }, [onResult, onInterim]);

  // æ¸…ç†é™éŸ³è¶…æ—¶
  const clearSilenceTimeout = useCallback(() => {
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
  }, []);

  // æ¸…ç†æ‰€æœ‰èµ„æº
  const cleanup = useCallback(() => {
    clearSilenceTimeout();

    // æ–­å¼€ AudioWorklet
    if (workletNodeRef.current) {
      workletNodeRef.current.disconnect();
      workletNodeRef.current = null;
    }

    // æ–­å¼€éŸ³é¢‘æº
    if (sourceRef.current) {
      sourceRef.current.disconnect();
      sourceRef.current = null;
    }

    // å…³é—­ AudioContext
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    // åœæ­¢ MediaStream
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    setMediaStream(null);

    // å…³é—­ WebSocket
    if (wsRef.current) {
      const ws = wsRef.current;
      wsRef.current = null;
      
      if (ws.readyState === WebSocket.OPEN) {
        // è¿æ¥å·²æ‰“å¼€ï¼Œå‘é€ç»“æŸä¿¡å·åå…³é—­
        ws.send(JSON.stringify({ type: 'end' }));
        ws.close();
      } else if (ws.readyState === WebSocket.CONNECTING) {
        // è¿æ¥ä¸­ï¼Œæ¸…ç©ºæ‰€æœ‰å›è°ƒé˜²æ­¢å½±å“æ–°çš„å½•éŸ³çŠ¶æ€ï¼Œç„¶ååœ¨è¿æ¥æˆåŠŸåå…³é—­
        ws.onopen = () => ws.close();
        ws.onclose = () => {};  // å¿½ç•¥å…³é—­äº‹ä»¶ï¼Œé˜²æ­¢å½±å“æ–°å½•éŸ³çš„ isRecording çŠ¶æ€
        ws.onmessage = () => {}; // å¿½ç•¥æ¶ˆæ¯
        ws.onerror = () => {}; // å¿½ç•¥è¿æ¥é”™è¯¯
      } else if (ws.readyState === WebSocket.CLOSING) {
        // æ­£åœ¨å…³é—­ï¼Œæ— éœ€æ“ä½œ
      } else {
        // å·²å…³é—­ï¼Œæ— éœ€æ“ä½œ
      }
    }
  }, [clearSilenceTimeout]);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      cleanup();
    };
  }, [cleanup]);

  // å®Œæˆå½•éŸ³å¹¶å‘é€ç»“æœ
  const finishRecording = useCallback(() => {
    // åˆå¹¶å·²ç´¯ç§¯æ–‡æœ¬å’Œå½“å‰å¥å­
    const text = (accumulatedTextRef.current + currentSentenceRef.current).trim();
    console.log('ğŸ¤ å½•éŸ³å®Œæˆ:', text);
    
    cleanup();
    setIsRecording(false);
    
    if (text) {
      onResultRef.current?.(text);
    }
    
    accumulatedTextRef.current = '';
    currentSentenceRef.current = '';
    setTranscript('');
  }, [cleanup]);

  // å¤„ç† WebSocket æ¶ˆæ¯
  const handleWsMessage = useCallback((event: MessageEvent) => {
    if (isStoppedRef.current) return;
    
    try {
      const response: TencentAsrResponse = JSON.parse(event.data);
      
      if (response.code !== 0) {
        console.error('ASR é”™è¯¯:', response.message);
        return;
      }

      if (response.result) {
        const text = response.result.voice_text_str;
        const isFinal = response.result.slice_type === ASR_SLICE_TYPE.END;
        
        clearSilenceTimeout();
        
        if (isFinal) {
          // VAD æ£€æµ‹åˆ°é™éŸ³ï¼Œå½“å‰å¥å­ç¡®è®¤å®Œæˆï¼Œç´¯ç§¯åˆ°æ€»æ–‡æœ¬
          accumulatedTextRef.current += text;
          currentSentenceRef.current = '';  // æ¸…ç©ºå½“å‰å¥å­
          setTranscript(accumulatedTextRef.current);
          onInterimRef.current?.(accumulatedTextRef.current);
          
          // è®¾ç½®é™éŸ³è¶…æ—¶ï¼Œç­‰å¾…å¯èƒ½çš„åç»­è¯­éŸ³
          silenceTimeoutRef.current = setTimeout(() => {
            if (!isStoppedRef.current) {
              finishRecording();
            }
          }, silenceTimeout);
        } else {
          // ä¸´æ—¶ç»“æœï¼šæ›¿æ¢å½“å‰å¥å­ï¼ˆä¸ç´¯åŠ ï¼‰ï¼Œæ˜¾ç¤º = å·²ç´¯ç§¯ + å½“å‰å¥å­
          currentSentenceRef.current = text;
          const displayText = accumulatedTextRef.current + text;
          setTranscript(displayText);
          onInterimRef.current?.(displayText);
        }
      }
    } catch {
      console.error('è§£æ ASR å“åº”å¤±è´¥');
    }
  }, [clearSilenceTimeout, finishRecording, silenceTimeout]);

  // åˆå§‹åŒ–éŸ³é¢‘å¤„ç†
  const initAudioProcessing = useCallback(async (
    ws: WebSocket,
    stream: MediaStream
  ) => {
    const audioContext = createAudioContext({ sampleRate: 16000 });
    audioContextRef.current = audioContext;
    
    // åŠ è½½ AudioWorklet æ¨¡å—
    try {
      await audioContext.audioWorklet.addModule(AUDIO_PROCESSOR_PATH);
    } catch (e) {
      console.error('åŠ è½½ AudioWorklet æ¨¡å—å¤±è´¥:', e);
      throw new Error('éŸ³é¢‘å¤„ç†æ¨¡å—åŠ è½½å¤±è´¥');
    }

    const source = audioContext.createMediaStreamSource(stream);
    sourceRef.current = source;

    const workletNode = new AudioWorkletNode(audioContext, AUDIO_PROCESSOR_NAME);
    workletNodeRef.current = workletNode;

    // å¤„ç†éŸ³é¢‘æ•°æ®
    workletNode.port.onmessage = (event) => {
      if (ws.readyState !== WebSocket.OPEN || isStoppedRef.current) return;
      const inputData: Float32Array = event.data;
      const pcmBuffer = audiaToPcmBuffer(inputData, audioContext.sampleRate);
      ws.send(pcmBuffer);
    };

    source.connect(workletNode);
    workletNode.connect(audioContext.destination);
  }, []);

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    if (isRecording) return;

    isStoppedRef.current = false;
    setError(null);
    accumulatedTextRef.current = '';
    currentSentenceRef.current = '';
    setTranscript('');

    try {
      console.log('ğŸ™ï¸ å¼€å§‹å®æ—¶è¯­éŸ³è¯†åˆ«...');

      // 1. è·å– WebSocket URL
      const urlResponse = await fetch('/api/asr/realtime');
      if (!urlResponse.ok) {
        throw new Error('è·å–è¯­éŸ³è¯†åˆ«è¿æ¥å¤±è´¥');
      }
      const { url: wsUrl } = await urlResponse.json();

      // 2. è·å–éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia(MICROPHONE_CONSTRAINTS);
      mediaStreamRef.current = stream;
      setMediaStream(stream);

      // 3. åˆ›å»º WebSocket è¿æ¥
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = async () => {
        console.log('ğŸ¤ ASR è¿æ¥æˆåŠŸ');
        setIsRecording(true);

        try {
          await initAudioProcessing(ws, stream);
        } catch (err) {
          setError(err instanceof Error ? err.message : 'éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥');
          cleanup();
        }
      };

      ws.onmessage = handleWsMessage;

      ws.onerror = () => {
        setError('è¯­éŸ³è¯†åˆ«è¿æ¥é”™è¯¯');
        cleanup();
        setIsRecording(false);
      };

      ws.onclose = () => {
        if (!isStoppedRef.current) {
          // è¿æ¥æ„å¤–å…³é—­ï¼Œè¿”å›å·²ç´¯ç§¯çš„ç»“æœï¼ˆåŒ…æ‹¬å½“å‰å¥å­ï¼‰
          const text = (accumulatedTextRef.current + currentSentenceRef.current).trim();
          if (text) {
            onResultRef.current?.(text);
          }
        }
        setIsRecording(false);
      };

    } catch (err) {
      console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', err);
      setError(err instanceof Error ? err.message : 'å¯åŠ¨å¤±è´¥');
      cleanup();
    }
  }, [isRecording, cleanup, initAudioProcessing, handleWsMessage]);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    isStoppedRef.current = true;
    clearSilenceTimeout();
    
    // åˆå¹¶å·²ç´¯ç§¯æ–‡æœ¬å’Œå½“å‰å¥å­çš„ä¸´æ—¶ç»“æœ
    const text = (accumulatedTextRef.current + currentSentenceRef.current).trim() || transcript.trim();
    cleanup();
    setIsRecording(false);
    
    // å¦‚æœæœ‰æ–‡æœ¬ï¼Œå‘é€ç»“æœ
    if (text) {
      onResultRef.current?.(text);
    }
    
    accumulatedTextRef.current = '';
    currentSentenceRef.current = '';
    setTranscript('');
  }, [cleanup, clearSilenceTimeout, transcript]);

  return {
    isRecording,
    transcript,
    error,
    mediaStream,
    startRecording,
    stopRecording,
  };
}
