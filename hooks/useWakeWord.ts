"use client";

import { useState, useRef, useCallback, useEffect } from 'react';
import { createAudioContext, audiaToPcmBuffer } from '@/utils/audio';
import { TencentAsrResponse, ASR_SLICE_TYPE } from '@/types/asr';
import {
  WAKE_WORD_COOLDOWN_MS,
  MAX_ACCUMULATED_TEXT_LENGTH,
  TRIM_TEXT_TO_LENGTH,
  WS_RECONNECT_DELAY,
  DEFAULT_WAKE_WORDS,
  AUDIO_PROCESSOR_PATH,
  AUDIO_PROCESSOR_NAME,
  MICROPHONE_CONSTRAINTS,
} from '@/constants/audio';

export interface UseWakeWordOptions {
  /** å”¤é†’è¯åˆ—è¡¨ */
  wakeWords?: string[];
  /** æ£€æµ‹åˆ°å”¤é†’è¯çš„å›è°ƒ */
  onWakeUp?: () => void;
}

export interface UseWakeWordReturn {
  /** æ˜¯å¦æ­£åœ¨ç›‘å¬ */
  isListening: boolean;
  /** é”™è¯¯ä¿¡æ¯ */
  error: string | null;
  /** å¼€å§‹ç›‘å¬ */
  startListening: () => Promise<void>;
  /** åœæ­¢ç›‘å¬ */
  stopListening: () => void;
}

/**
 * è¯­éŸ³å”¤é†’ Hook - æŒç»­ç›‘å¬å”¤é†’è¯
 * 
 * é€šè¿‡æ§åˆ¶å°å¯ç”¨ï¼š
 * window.startWakeWord()  // å¼€å§‹ç›‘å¬
 * window.stopWakeWord()   // åœæ­¢ç›‘å¬
 */
export function useWakeWord(options: UseWakeWordOptions = {}): UseWakeWordReturn {
  const {
    wakeWords = DEFAULT_WAKE_WORDS,
    onWakeUp,
  } = options;

  // State
  const [isListening, setIsListening] = useState(false);
  const [error, setError] = useState<string | null>(null);

  // Refs - èµ„æºå¼•ç”¨
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  
  // Refs - çŠ¶æ€å¼•ç”¨
  const accumulatedTextRef = useRef('');
  const lastWakeUpTimeRef = useRef(0);
  const isManualStopRef = useRef(false);
  const reconnectTimeoutRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  
  // Refs - å›è°ƒå¼•ç”¨
  const onWakeUpRef = useRef(onWakeUp);
  
  useEffect(() => {
    onWakeUpRef.current = onWakeUp;
  }, [onWakeUp]);

  // å»é™¤æ ‡ç‚¹ç¬¦å·ï¼ˆç”¨äºå”¤é†’è¯åŒ¹é…ï¼‰
  const removePunctuation = useCallback((text: string): string => {
    return text
      .toLowerCase()
      .replace(/[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ã€ã€‘ã€Šã€‹ï¼ˆï¼‰â€¦â€”ï½Â·,.!?;:'"()\[\]{}<>@#$%^&*+=|\\/_-]/g, '')
      .replace(/\s+/g, '');
  }, []);

  // æ£€æŸ¥å”¤é†’è¯
  const checkWakeWord = useCallback((text: string): boolean => {
    const normalizedText = removePunctuation(text);
    return wakeWords.some(word => normalizedText.includes(removePunctuation(word)));
  }, [wakeWords, removePunctuation]);

  // æ¸…ç†æ‰€æœ‰èµ„æº
  const cleanup = useCallback(() => {
    // æ¸…ç†é‡è¿å®šæ—¶å™¨
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current);
      reconnectTimeoutRef.current = null;
    }

    // æ–­å¼€ AudioWorklet
    if (workletNodeRef.current) {
      workletNodeRef.current.disconnect();
      workletNodeRef.current = null;
    }

    // æ–­å¼€éŸ³é¢‘æº
    if (sourceRef.current) {
      sourceRef.current.disconnect();
      sourceRef.current = null;
    }

    // å…³é—­ AudioContext
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    // åœæ­¢ MediaStream
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }

    // å…³é—­ WebSocket
    if (wsRef.current) {
      wsRef.current.close();
      wsRef.current = null;
    }
  }, []);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      isManualStopRef.current = true;
      cleanup();
    };
  }, [cleanup]);

  // åˆå§‹åŒ–éŸ³é¢‘å¤„ç†
  const initAudioProcessing = useCallback(async (
    ws: WebSocket,
    stream: MediaStream
  ) => {
    const audioContext = createAudioContext({ sampleRate: 16000 });
    audioContextRef.current = audioContext;

    try {
      await audioContext.audioWorklet.addModule(AUDIO_PROCESSOR_PATH);
    } catch (e) {
      console.error('åŠ è½½ AudioWorklet æ¨¡å—å¤±è´¥:', e);
      throw new Error('éŸ³é¢‘å¤„ç†æ¨¡å—åŠ è½½å¤±è´¥');
    }

    const source = audioContext.createMediaStreamSource(stream);
    sourceRef.current = source;

    const workletNode = new AudioWorkletNode(audioContext, AUDIO_PROCESSOR_NAME);
    workletNodeRef.current = workletNode;

    workletNode.port.onmessage = (event) => {
      if (ws.readyState !== WebSocket.OPEN) return;
      const inputData: Float32Array = event.data;
      const pcmBuffer = audiaToPcmBuffer(inputData, audioContext.sampleRate);
      ws.send(pcmBuffer);
    };

    source.connect(workletNode);
    workletNode.connect(audioContext.destination);
  }, []);

  // å¤„ç† WebSocket æ¶ˆæ¯
  const handleWsMessage = useCallback((event: MessageEvent) => {
    try {
      const response: TencentAsrResponse = JSON.parse(event.data);
      
      if (response.code !== 0 || !response.result) return;

      const text = response.result.voice_text_str;
      const isFinal = response.result.slice_type === ASR_SLICE_TYPE.END;

      // ç´¯ç§¯æœ€ç»ˆç»“æœ
      if (isFinal) {
        accumulatedTextRef.current += text;
      }

      // æ£€æŸ¥å”¤é†’è¯
      const textToCheck = isFinal 
        ? accumulatedTextRef.current 
        : accumulatedTextRef.current + text;
      
      const now = Date.now();
      const cooldownElapsed = now - lastWakeUpTimeRef.current > WAKE_WORD_COOLDOWN_MS;

      if (checkWakeWord(textToCheck) && cooldownElapsed) {
        console.log('âœ… æ£€æµ‹åˆ°å”¤é†’è¯:', textToCheck);
        lastWakeUpTimeRef.current = now;
        accumulatedTextRef.current = '';
        onWakeUpRef.current?.();
      }

      // é˜²æ­¢ç´¯ç§¯æ–‡æœ¬è¿‡é•¿
      if (accumulatedTextRef.current.length > MAX_ACCUMULATED_TEXT_LENGTH) {
        accumulatedTextRef.current = accumulatedTextRef.current.slice(-TRIM_TEXT_TO_LENGTH);
      }
    } catch {
      // å¿½ç•¥è§£æé”™è¯¯
    }
  }, [checkWakeWord]);

  // å¼€å§‹ç›‘å¬ï¼ˆå£°æ˜æå‰ä»¥ä¾¿ handleWsClose å¼•ç”¨ï¼‰
  const startListeningRef = useRef<() => Promise<void>>(undefined);

  // å¤„ç† WebSocket å…³é—­
  const handleWsClose = useCallback(() => {
    setIsListening(false);
    
    // éæ‰‹åŠ¨åœæ­¢æ—¶è‡ªåŠ¨é‡è¿
    if (!isManualStopRef.current) {
      reconnectTimeoutRef.current = setTimeout(() => {
        if (!isManualStopRef.current) {
          cleanup();
          startListeningRef.current?.();
        }
      }, WS_RECONNECT_DELAY);
    }
  }, [cleanup]);

  // å¼€å§‹ç›‘å¬
  const startListening = useCallback(async () => {
    if (isListening) return;

    isManualStopRef.current = false;
    setError(null);
    accumulatedTextRef.current = '';

    try {
      console.log('ğŸ¤ å¼€å§‹ç›‘å¬å”¤é†’è¯...');

      // è·å– WebSocket URL
      const urlResponse = await fetch('/api/asr/realtime');
      if (!urlResponse.ok) {
        throw new Error('è·å–è¿æ¥å¤±è´¥');
      }
      const { url: wsUrl } = await urlResponse.json();

      // è·å–éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia(MICROPHONE_CONSTRAINTS);
      mediaStreamRef.current = stream;

      // åˆ›å»º WebSocket è¿æ¥
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = async () => {
        console.log('ğŸ¤ å”¤é†’ç›‘å¬å·²å¯åŠ¨');
        setIsListening(true);

        try {
          await initAudioProcessing(ws, stream);
        } catch (err) {
          setError(err instanceof Error ? err.message : 'éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥');
          cleanup();
        }
      };

      ws.onmessage = handleWsMessage;

      ws.onerror = () => {
        setError('è¿æ¥é”™è¯¯');
        cleanup();
        setIsListening(false);
      };

      ws.onclose = handleWsClose;

    } catch (err) {
      console.error('å¯åŠ¨å”¤é†’ç›‘å¬å¤±è´¥:', err);
      setError(err instanceof Error ? err.message : 'å¯åŠ¨å¤±è´¥');
      cleanup();
    }
  }, [isListening, cleanup, initAudioProcessing, handleWsMessage, handleWsClose]);

  // æ›´æ–° ref
  useEffect(() => {
    startListeningRef.current = startListening;
  }, [startListening]);

  // åœæ­¢ç›‘å¬
  const stopListening = useCallback(() => {
    console.log('ğŸ¤ åœæ­¢å”¤é†’ç›‘å¬');
    isManualStopRef.current = true;
    cleanup();
    setIsListening(false);
    accumulatedTextRef.current = '';
  }, [cleanup]);

  return {
    isListening,
    error,
    startListening,
    stopListening,
  };
}
